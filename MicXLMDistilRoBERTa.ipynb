{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "640574d0334943979d6b6b934c48bd1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99599daaaf6a4ec9a089d7d0299b33e8",
              "IPY_MODEL_d8c3b3b308414b51b0b9f2f4bd9ef29d",
              "IPY_MODEL_ab815256d806451ab18d4bfa45dc8bd8"
            ],
            "layout": "IPY_MODEL_e0be395af1ce4da9a1d0fe46edd56736"
          }
        },
        "99599daaaf6a4ec9a089d7d0299b33e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_305cf2885fe64f41ba2e8862ad1e9a5b",
            "placeholder": "​",
            "style": "IPY_MODEL_2fbca80deb2e43628f53a9dc385005d6",
            "value": "Map: 100%"
          }
        },
        "d8c3b3b308414b51b0b9f2f4bd9ef29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a2d82ddf82140a98da5b2238b5b5970",
            "max": 36,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8fa72bab7c143e286a305a8726e2d04",
            "value": 36
          }
        },
        "ab815256d806451ab18d4bfa45dc8bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc46905803c44fe91ee57e9eec6ae4c",
            "placeholder": "​",
            "style": "IPY_MODEL_46c7aa2c3a7b4b9481b0d3ef0903f857",
            "value": " 36/36 [00:00&lt;00:00, 1650.00 examples/s]"
          }
        },
        "e0be395af1ce4da9a1d0fe46edd56736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305cf2885fe64f41ba2e8862ad1e9a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fbca80deb2e43628f53a9dc385005d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a2d82ddf82140a98da5b2238b5b5970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8fa72bab7c143e286a305a8726e2d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bc46905803c44fe91ee57e9eec6ae4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c7aa2c3a7b4b9481b0d3ef0903f857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d2cbe779b949a8aa17378d867a5e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4c0f7037bcf4532b583a212fb716818",
              "IPY_MODEL_55f4c4419b80446d8d7df2523637ff21",
              "IPY_MODEL_788ac0407be349128c165dd57ab54bad"
            ],
            "layout": "IPY_MODEL_a9f12b58ca4c4deab13e35646fa2d3fd"
          }
        },
        "a4c0f7037bcf4532b583a212fb716818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24c0ad987a774841bf15b56888c6e54d",
            "placeholder": "​",
            "style": "IPY_MODEL_0064f75a64ad4ee296d87e097fded169",
            "value": "Map: 100%"
          }
        },
        "55f4c4419b80446d8d7df2523637ff21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac16c18421e49b794617fd5b29a38f5",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d100093a2082408698b7293fec9bc837",
            "value": 9
          }
        },
        "788ac0407be349128c165dd57ab54bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3722176ea4a42e09e12b1ac5d30be7f",
            "placeholder": "​",
            "style": "IPY_MODEL_447e114aaa894763a8770f7371bccc51",
            "value": " 9/9 [00:00&lt;00:00, 461.48 examples/s]"
          }
        },
        "a9f12b58ca4c4deab13e35646fa2d3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24c0ad987a774841bf15b56888c6e54d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0064f75a64ad4ee296d87e097fded169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ac16c18421e49b794617fd5b29a38f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d100093a2082408698b7293fec9bc837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3722176ea4a42e09e12b1ac5d30be7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447e114aaa894763a8770f7371bccc51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "1hLI9PxAib9p"
      },
      "outputs": [],
      "source": [
        "#import shutil\n",
        "#shutil.rmtree('/content/metrics', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Microsoft XtremeDistil RoBERTa"
      ],
      "metadata": {
        "id": "bhDjh5mzyr89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import Dataset\n",
        "import tempfile\n",
        "import subprocess\n",
        "import sys"
      ],
      "metadata": {
        "id": "W0myOdmuy4zv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT LIBRARIES AND SETUP"
      ],
      "metadata": {
        "id": "aZVkzzqjy9GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def install_requirements():\n",
        "    required_packages = [\n",
        "        'transformers[torch]',\n",
        "        'datasets',\n",
        "        'torch',\n",
        "        'pandas',\n",
        "        'scikit-learn',\n",
        "        'onnx',\n",
        "        'onnxruntime',\n",
        "        'optimum[onnxruntime]',  # This enables ORTModelForSequenceClassification\n",
        "        'tensorflow',\n",
        "    ]\n",
        "\n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            __import__(package.split('[')[0])\n",
        "        except ImportError:\n",
        "            print(f\"Installing {package}...\")\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])"
      ],
      "metadata": {
        "id": "xuFj1VR9zB17"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Checking and installing dependencies...\")\n",
        "install_requirements()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HyDQhrtzIR6",
        "outputId": "3ebb2c38-eb7b-4481-aa48-a1495e00355a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking and installing dependencies...\n",
            "Installing scikit-learn...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from optimum.onnxruntime import ORTModelForSequenceClassification\n",
        "    from optimum.onnxruntime.configuration import OptimizationConfig\n",
        "    ONNX_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Optimum ONNX Runtime not available, ONNX export will be limited\")\n",
        "    ONNX_AVAILABLE = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub1LCZ4mzJ7h",
        "outputId": "e5a695b1-4d7b-46b1-8781-cf9b3c0e7240"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimum ONNX Runtime not available, ONNX export will be limited\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All dependencies loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1GWDzAMzLXF",
        "outputId": "1c08b8dc-11ad-4cc4-9e95-57f58bc1667e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dependencies loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD AND PREPARE DATASET"
      ],
      "metadata": {
        "id": "oeb5zzXczNlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(csv_path='dataset.csv'):\n",
        "    print(f\"Loading dataset from {csv_path}...\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
        "\n",
        "        # Validate required columns\n",
        "        required_cols = ['text', 'label']\n",
        "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "        if missing_cols:\n",
        "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "        # Clean and validate data\n",
        "        df = df.dropna(subset=['text', 'label'])\n",
        "        df['text'] = df['text'].astype(str)\n",
        "        df['label'] = df['label'].astype(int)\n",
        "\n",
        "        # Check label range - XtremeDistil can handle multi-class classification\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        num_labels = len(unique_labels)\n",
        "\n",
        "        # Ensure labels are sequential starting from 0\n",
        "        if unique_labels != list(range(num_labels)):\n",
        "            print(\"Warning: Labels are not sequential starting from 0. Remapping...\")\n",
        "            label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
        "            df['label'] = df['label'].map(label_mapping)\n",
        "            print(f\"Label mapping: {label_mapping}\")\n",
        "\n",
        "        print(f\"Dataset validation complete. Clean shape: {df.shape}\")\n",
        "        print(f\"Number of classes: {num_labels}\")\n",
        "\n",
        "        # Updated label descriptions for NSFW/Safe classification\n",
        "        if num_labels == 2:\n",
        "            print(\"Binary classification detected - assuming NSFW/Safe task\")\n",
        "            print(\"Label distribution:\")\n",
        "            label_counts = df['label'].value_counts().sort_index()\n",
        "            for label, count in label_counts.items():\n",
        "                label_name = \"Safe\" if label == 0 else \"NSFW\"\n",
        "                print(f\"  {label} ({label_name}): {count} samples\")\n",
        "        else:\n",
        "            print(f\"Label distribution:\\n{df['label'].value_counts().sort_index()}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Dataset file '{csv_path}' not found!\")\n",
        "        print(\"Creating a sample NSFW/Safe classification dataset for demonstration...\")\n",
        "        return create_sample_dataset()"
      ],
      "metadata": {
        "id": "T0W7yP2izQL2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_dataset():\n",
        "    sample_data = {\n",
        "        'text': [\n",
        "            # Safe content (label 0) - combining positive and neutral examples\n",
        "            'I love this product, it works perfectly!',\n",
        "            'This is an amazing experience, highly recommended!',\n",
        "            'Great quality and fast delivery service.',\n",
        "            'Excellent customer support and user-friendly interface.',\n",
        "            'Outstanding performance and great value for money.',\n",
        "            'The product is okay, nothing special about it.',\n",
        "            'Average quality, meets basic requirements.',\n",
        "            'It works as described, no complaints.',\n",
        "            'Standard features, typical for this price range.',\n",
        "            'Normal delivery time, packaging was fine.',\n",
        "            'Me encanta este producto, funciona perfectamente.',\n",
        "            'Excelente calidad y servicio rápido.',\n",
        "            'El producto está bien, nada especial.',\n",
        "            'Calidad promedio, cumple con lo básico.',\n",
        "            'Napakaganda ng produktong ito, sulit na sulit.',\n",
        "            'Magandang serbisyo at mabilis na delivery.',\n",
        "            'Okay lang ang produkto, walang masama.',\n",
        "            'Standard quality, normal lang.',\n",
        "            'Produit excellent, je le recommande vivement.',\n",
        "            'Service client formidable et livraison rapide.',\n",
        "            'Produit correct, sans plus.',\n",
        "            'This is a family-friendly movie everyone can enjoy.',\n",
        "            'Educational content about science and technology.',\n",
        "            'Safe workplace environment and policies.',\n",
        "            'Appropriate content for all age groups.',\n",
        "\n",
        "            # NSFW content (label 1) - inappropriate/explicit content\n",
        "            'This contains explicit adult content not suitable for minors.',\n",
        "            'Inappropriate sexual references and mature themes.',\n",
        "            'Contains graphic violence and disturbing imagery.',\n",
        "            'Adult-oriented material with explicit language.',\n",
        "            'Mature content with sexual themes and nudity.',\n",
        "            'Violent and disturbing content not for children.',\n",
        "            'Explicit adult entertainment material.',\n",
        "            'Contains profanity and inappropriate behavior.',\n",
        "            'Mature themes including alcohol and substance abuse.',\n",
        "            'Graphic content with adult situations.',\n",
        "            'Inappropriate workplace behavior and harassment.',\n",
        "            'Explicit material containing adult themes.',\n",
        "            'Disturbing content with mature subject matter.',\n",
        "            'Adult content with sexual references.',\n",
        "            'Inappropriate material for general audiences.',\n",
        "            'Mature content with explicit themes.',\n",
        "            'Adult-oriented discussions and topics.',\n",
        "            'Inappropriate behavior and language.',\n",
        "            'Explicit content not suitable for work.',\n",
        "            'Mature themes and adult situations.',\n",
        "        ],\n",
        "        'label': (\n",
        "            [0] * 25 +  # 25 safe content samples (combining positive/neutral)\n",
        "            [1] * 20    # 20 NSFW content samples\n",
        "        )\n",
        "    }\n",
        "\n",
        "    # Safety check to ensure equal lengths\n",
        "    if len(sample_data['text']) != len(sample_data['label']):\n",
        "        print(f\"WARNING: Length mismatch! Text: {len(sample_data['text'])}, Label: {len(sample_data['label'])}\")\n",
        "        min_len = min(len(sample_data['text']), len(sample_data['label']))\n",
        "        sample_data['text'] = sample_data['text'][:min_len]\n",
        "        sample_data['label'] = sample_data['label'][:min_len]\n",
        "\n",
        "    df = pd.DataFrame(sample_data)\n",
        "    df.to_csv('dataset.csv', index=False)\n",
        "    print(\"Sample NSFW/Safe classification dataset created and saved as 'dataset.csv'\")\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "    print(\"Label mapping: 0 = Safe, 1 = NSFW\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "g3-QeWn7zUoN"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(df, test_size=0.2, random_state=42):\n",
        "    print(f\"Splitting dataset: {test_size*100}% for validation...\")\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        df['text'].tolist(),\n",
        "        df['label'].tolist(),\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=df['label']\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(X_train)} samples\")\n",
        "    print(f\"Validation set: {len(X_val)} samples\")\n",
        "\n",
        "    return X_train, X_val, y_train, y_val"
      ],
      "metadata": {
        "id": "hjkeXR_lzdKL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENIZATION AND PREPROCESSING"
      ],
      "metadata": {
        "id": "jgHjjboIzgnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tokenized_datasets(X_train, X_val, y_train, y_val, model_name):\n",
        "    \"\"\"Tokenize the datasets using the XtremeDistil tokenizer\"\"\"\n",
        "    print(\"Loading XtremeDistil tokenizer and creating tokenized datasets...\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # XtremeDistil uses BERT-style tokenization\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.unk_token if tokenizer.unk_token is not None else '[PAD]'\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = Dataset.from_dict({\n",
        "        'text': X_train,\n",
        "        'labels': y_train\n",
        "    })\n",
        "\n",
        "    val_dataset = Dataset.from_dict({\n",
        "        'text': X_val,\n",
        "        'labels': y_val\n",
        "    })\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            truncation=True,\n",
        "            padding=False,  # Will be handled by data collator\n",
        "            max_length=128  # XtremeDistil works well with shorter sequences\n",
        "        )\n",
        "\n",
        "    # Tokenize datasets\n",
        "    train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
        "    val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    print(\"Tokenization complete!\")\n",
        "    print(f\"Sample tokenized text length: {len(train_tokenized[0]['input_ids'])}\")\n",
        "\n",
        "    return train_tokenized, val_tokenized, tokenizer"
      ],
      "metadata": {
        "id": "Jso7t-2RzkGH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING"
      ],
      "metadata": {
        "id": "-xzDJDv5zmAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataset, val_dataset, tokenizer, model_name, output_dir, num_labels):\n",
        "    \"\"\"Train the XtremeDistil model for multilingual classification\"\"\"\n",
        "    print(\"Initializing XtremeDistil model for multilingual classification training...\")\n",
        "\n",
        "    # Load model with appropriate number of labels\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=num_labels,\n",
        "        problem_type=\"single_label_classification\"\n",
        "    )\n",
        "\n",
        "    # Ensure model uses the correct pad_token_id\n",
        "    if tokenizer.pad_token_id is not None:\n",
        "        model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    # Data collator\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    # Training arguments optimized for XtremeDistil\n",
        "    training_args_dict = {\n",
        "        'output_dir': output_dir,\n",
        "        'num_train_epochs': 4,  # Slightly more epochs due to distilled model\n",
        "        'per_device_train_batch_size': 16,  # Larger batch size (smaller model)\n",
        "        'per_device_eval_batch_size': 16,\n",
        "        'learning_rate': 5e-5,  # Higher learning rate for distilled models\n",
        "        'weight_decay': 0.01,\n",
        "        'warmup_ratio': 0.1,  # Warmup ratio instead of steps\n",
        "        'logging_dir': f'{output_dir}/logs',\n",
        "        'logging_steps': 10,\n",
        "        'save_total_limit': 2,\n",
        "        'load_best_model_at_end': True,\n",
        "        'metric_for_best_model': \"eval_f1_macro\",\n",
        "        'greater_is_better': True,\n",
        "        'report_to': [],\n",
        "        'seed': 42,\n",
        "        'dataloader_num_workers': 0,\n",
        "        'remove_unused_columns': True,\n",
        "        'fp16': True,  # Mixed precision for efficiency\n",
        "        'dataloader_pin_memory': False,\n",
        "        'gradient_checkpointing': False,  # XtremeDistil is small enough\n",
        "    }\n",
        "\n",
        "    # Add version-specific parameters\n",
        "    if hasattr(TrainingArguments, 'eval_strategy'):\n",
        "        training_args_dict['eval_strategy'] = \"epoch\"\n",
        "        training_args_dict['save_strategy'] = \"epoch\"\n",
        "    else:\n",
        "        training_args_dict['evaluation_strategy'] = \"epoch\"\n",
        "        training_args_dict['save_strategy'] = \"epoch\"\n",
        "\n",
        "    training_args = TrainingArguments(**training_args_dict)\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "\n",
        "        # Handle different prediction formats\n",
        "        if isinstance(predictions, tuple):\n",
        "            predictions = predictions[0]\n",
        "\n",
        "        # Convert to numpy array if it's a tensor\n",
        "        if hasattr(predictions, 'numpy'):\n",
        "            predictions = predictions.numpy()\n",
        "\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "        f1_macro = f1_score(labels, predictions, average='macro')\n",
        "        f1_weighted = f1_score(labels, predictions, average='weighted')\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "        }\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the best model\n",
        "    print(f\"Saving model to {output_dir}...\")\n",
        "    trainer.save_model()\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    return trainer, model"
      ],
      "metadata": {
        "id": "7ukeIKY0zrTM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL EVALUATION"
      ],
      "metadata": {
        "id": "m6N26bVazuuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(trainer, X_val, y_val, output_dir, num_labels):\n",
        "    print(\"Evaluating model performance...\")\n",
        "\n",
        "    # Get predictions\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    # Get detailed predictions for classification report\n",
        "    predictions = trainer.predict(trainer.eval_dataset)\n",
        "\n",
        "    # Extract predictions from the prediction object\n",
        "    if hasattr(predictions, 'predictions'):\n",
        "        preds = predictions.predictions\n",
        "    else:\n",
        "        preds = predictions[0]\n",
        "\n",
        "    # Convert to numpy array if it's a tensor\n",
        "    if hasattr(preds, 'numpy'):\n",
        "        preds = preds.numpy()\n",
        "\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "    # Generate classification report with updated target names\n",
        "    if num_labels == 2:\n",
        "        target_names = ['Safe', 'NSFW']  # This part works correctly\n",
        "    elif num_labels == 3:\n",
        "        target_names = ['Positive', 'Neutral', 'Negative']\n",
        "    else:\n",
        "        target_names = [f'Class_{i}' for i in range(num_labels)]\n",
        "\n",
        "    report = classification_report(\n",
        "        y_val,\n",
        "        y_pred,\n",
        "        target_names=target_names,\n",
        "        digits=4\n",
        "    )\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    f1_macro = f1_score(y_val, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_val, y_pred, average='weighted')\n",
        "\n",
        "    # Updated metrics text for NSFW/Safe classification\n",
        "    metrics_text = f\"\"\"XtremeDistil NSFW/Safe Classification Model Evaluation Results\n",
        "{'='*70}\n",
        "\n",
        "Model: microsoft/xtremedistil-l6-h384-uncased\n",
        "Task: NSFW/Safe Content Classification (Binary Classification)\n",
        "Architecture: 6 layers, 384 hidden units (Distilled)\n",
        "\n",
        "Classification Labels:\n",
        "- 0: Safe Content\n",
        "- 1: NSFW Content\n",
        "\n",
        "Performance Metrics:\n",
        "{'-'*30}\n",
        "Accuracy: {accuracy:.4f}\n",
        "F1-Score (Macro): {f1_macro:.4f}\n",
        "F1-Score (Weighted): {f1_weighted:.4f}\n",
        "\n",
        "Classification Report:\n",
        "{report}\n",
        "\n",
        "Training Results:\n",
        "{'-'*30}\n",
        "\"\"\"\n",
        "\n",
        "    for key, value in eval_results.items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            metrics_text += f\"{key}: {value:.4f}\\n\"\n",
        "\n",
        "    # Save metrics\n",
        "    os.makedirs('metrics', exist_ok=True)\n",
        "    metrics_path = 'metrics/xtremedistil_nsfw_safe_metrics.txt'\n",
        "\n",
        "    with open(metrics_path, 'w') as f:\n",
        "        f.write(metrics_text)\n",
        "\n",
        "    print(f\"Metrics saved to {metrics_path}\")\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
        "\n",
        "    return accuracy, report"
      ],
      "metadata": {
        "id": "eiIwik6szzJb"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX EXPORT"
      ],
      "metadata": {
        "id": "W80G-a7Sz1xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_onnx(model_dir, onnx_path):\n",
        "    print(\"Exporting XtremeDistil NSFW/Safe classification model to ONNX format...\")\n",
        "\n",
        "    try:\n",
        "        # Load the trained model\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "        # Create dummy input with NSFW/Safe classification sample\n",
        "        dummy_input = tokenizer(\n",
        "            \"This is a sample text for NSFW/Safe classification ONNX export\",\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=128,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        # Export to ONNX with optimization for XtremeDistil\n",
        "        os.makedirs(os.path.dirname(onnx_path), exist_ok=True)\n",
        "        torch.onnx.export(\n",
        "            model,\n",
        "            tuple(dummy_input.values()),\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=14,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['input_ids', 'attention_mask'],\n",
        "            output_names=['logits'],\n",
        "            dynamic_axes={\n",
        "                'input_ids': {0: 'batch_size', 1: 'sequence'},\n",
        "                'attention_mask': {0: 'batch_size', 1: 'sequence'},\n",
        "                'logits': {0: 'batch_size'}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(f\"ONNX model exported to: {onnx_path}\")\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
        "        print(f\"ONNX model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ONNX export failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ],
      "metadata": {
        "id": "YgVs2O6Pz5uh"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TENSORFLOW LITE EXPORT"
      ],
      "metadata": {
        "id": "6MJj9vhfz8Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_to_tflite_from_pt(model_dir, tflite_path):\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "        from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "        print(\"Converting XtremeDistil NSFW/Safe PyTorch model to TensorFlow...\")\n",
        "\n",
        "        # Load and convert to TensorFlow\n",
        "        tf_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "            model_dir,\n",
        "            from_pt=True\n",
        "        )\n",
        "\n",
        "        # Save as TensorFlow SavedModel\n",
        "        tf_saved_model_dir = os.path.join(model_dir, \"tf_saved_model\")\n",
        "        tf.saved_model.save(tf_model, tf_saved_model_dir)\n",
        "        print(f\"Saved intermediate TensorFlow model to {tf_saved_model_dir}\")\n",
        "\n",
        "        # Convert to TFLite with optimizations\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(tf_saved_model_dir)\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "        # Additional optimizations for mobile deployment\n",
        "        converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        # Save TFLite model\n",
        "        os.makedirs(os.path.dirname(tflite_path), exist_ok=True)\n",
        "        with open(tflite_path, \"wb\") as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "        print(f\"TFLite NSFW/Safe classification model successfully exported to: {tflite_path}\")\n",
        "        print(f\"TFLite model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"TensorFlow Lite export failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ],
      "metadata": {
        "id": "sRZu1baAz_ko"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "H_FRO89y0Aen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Starting XtremeDistil NSFW/Safe Content Classification Pipeline\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Configuration - Updated paths for NSFW/Safe classification\n",
        "    MODEL_NAME = \"microsoft/xtremedistil-l6-h384-uncased\"\n",
        "    OUTPUT_DIR = \"models/xtremedistil_nsfw_safe_classification\"\n",
        "    ONNX_PATH = \"models/xtremedistil_nsfw_safe_model.onnx\"\n",
        "    TFLITE_PATH = \"models/xtremedistil_nsfw_safe_model.tflite\"\n",
        "\n",
        "    # Create output directories\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    os.makedirs(\"metrics\", exist_ok=True)\n",
        "\n",
        "    print(f\"Using model: {MODEL_NAME}\")\n",
        "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "    print(\"Task: Binary classification (Safe vs NSFW content)\")\n",
        "\n",
        "    # Step 1: Load dataset\n",
        "    df = load_dataset()\n",
        "    num_labels = len(df['label'].unique())\n",
        "    print(f\"Number of classes detected: {num_labels}\")\n",
        "\n",
        "    # Step 2: Split dataset\n",
        "    X_train, X_val, y_train, y_val = split_dataset(df)\n",
        "\n",
        "    # Step 3: Create tokenized datasets\n",
        "    train_dataset, val_dataset, tokenizer = create_tokenized_datasets(\n",
        "        X_train, X_val, y_train, y_val, MODEL_NAME\n",
        "    )\n",
        "\n",
        "    # Step 4: Train model\n",
        "    trainer, model = train_model(\n",
        "        train_dataset, val_dataset, tokenizer, MODEL_NAME, OUTPUT_DIR, num_labels\n",
        "    )\n",
        "\n",
        "    # Step 5: Evaluate model\n",
        "    accuracy, report = evaluate_model(trainer, X_val, y_val, OUTPUT_DIR, num_labels)\n",
        "\n",
        "    # Step 6: Export to ONNX\n",
        "    onnx_success = export_to_onnx(OUTPUT_DIR, ONNX_PATH)\n",
        "\n",
        "    # Step 7: Export to TFLite\n",
        "    tflite_success = export_to_tflite_from_pt(OUTPUT_DIR, TFLITE_PATH)\n",
        "\n",
        "    # Final output\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"XtremeDistil NSFW/Safe Content Classification Training Complete!\")\n",
        "\n",
        "    if onnx_success:\n",
        "        print(f\"✅ ONNX model: {ONNX_PATH}\")\n",
        "    else:\n",
        "        print(\"❌ ONNX export: FAILED\")\n",
        "\n",
        "    if tflite_success:\n",
        "        print(f\"✅ TFLite model: {TFLITE_PATH}\")\n",
        "    else:\n",
        "        print(\"❌ TFLite export: FAILED\")\n",
        "\n",
        "    print(f\"\\nModel checkpoints: {OUTPUT_DIR}\")\n",
        "    print(f\"Metrics: metrics/xtremedistil_nsfw_safe_metrics.txt\")\n",
        "    print(f\"Final validation accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nModel can classify content as:\")\n",
        "    print(\"- 0: Safe content\")\n",
        "    print(\"- 1: NSFW content\")"
      ],
      "metadata": {
        "id": "aTzx_Np30Emi"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INFERENCE"
      ],
      "metadata": {
        "id": "c3F1SiM80FhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_inference(model_dir, test_texts=None):\n",
        "    if test_texts is None:\n",
        "        test_texts = [\n",
        "            # Safe content examples\n",
        "            \"I absolutely love this product, it's amazing!\",\n",
        "            \"This is a family-friendly educational video about science.\",\n",
        "            \"Great customer service and fast delivery.\",\n",
        "            \"The movie is appropriate for all age groups.\",\n",
        "            \"This workspace follows safety guidelines.\",\n",
        "\n",
        "            # Spanish safe content\n",
        "            \"Me encanta este producto, es fantástico.\",\n",
        "            \"Contenido educativo apropiado para toda la familia.\",\n",
        "\n",
        "            # Tagalog safe content\n",
        "            \"Napakaganda ng produktong ito, sulit na sulit!\",\n",
        "            \"Magandang palabas para sa buong pamilya.\",\n",
        "\n",
        "            # French safe content\n",
        "            \"J'adore ce produit, il est formidable!\",\n",
        "            \"Contenu familial et éducatif.\",\n",
        "\n",
        "            # NSFW content examples\n",
        "            \"This contains explicit adult content not suitable for minors.\",\n",
        "            \"Inappropriate sexual references and mature themes.\",\n",
        "            \"Contains graphic violence and disturbing imagery.\",\n",
        "            \"Adult-oriented material with explicit language.\",\n",
        "            \"Mature content with sexual themes.\",\n",
        "            \"Violent content not suitable for children.\",\n",
        "        ]\n",
        "\n",
        "    print(\"\\nTesting trained XtremeDistil NSFW/Safe classification model...\")\n",
        "\n",
        "    try:\n",
        "        # Load model and tokenizer\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Determine label names based on number of labels\n",
        "        num_labels = model.config.num_labels\n",
        "        if num_labels == 2:\n",
        "            label_names = [\"Safe\", \"NSFW\"]  # Updated for NSFW/Safe classification\n",
        "        elif num_labels == 3:\n",
        "            label_names = [\"Positive\", \"Neutral\", \"Negative\"]\n",
        "        else:\n",
        "            label_names = [f\"Class_{i}\" for i in range(num_labels)]\n",
        "\n",
        "        for i, text in enumerate(test_texts):\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=128,\n",
        "                padding=True\n",
        "            )\n",
        "\n",
        "            # Predict\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "                predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "                confidence = predictions[0][predicted_class].item()\n",
        "\n",
        "            # Map predictions to labels\n",
        "            label = label_names[predicted_class] if predicted_class < len(label_names) else f\"Class_{predicted_class}\"\n",
        "\n",
        "            print(f\"Text {i+1}: '{text}'\")\n",
        "            print(f\"  -> {label} (confidence: {confidence:.4f})\")\n",
        "\n",
        "            # Show all probabilities\n",
        "            probs_str = \", \".join([f\"{label_names[j] if j < len(label_names) else f'Class_{j}'}={predictions[0][j].item():.3f}\"\n",
        "                                 for j in range(num_labels)])\n",
        "            print(f\"  Probabilities: {probs_str}\")\n",
        "            print()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Inference test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "nrs5625v0J_0"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROGRAM EXECUTION"
      ],
      "metadata": {
        "id": "XuZlk4iQ0MK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Run the main pipeline\n",
        "        main()\n",
        "\n",
        "        # Optional: Test inference\n",
        "        test_inference(\"models/xtremedistil_nsfw_safe_classification\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nTraining interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\nProgram execution completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "640574d0334943979d6b6b934c48bd1c",
            "99599daaaf6a4ec9a089d7d0299b33e8",
            "d8c3b3b308414b51b0b9f2f4bd9ef29d",
            "ab815256d806451ab18d4bfa45dc8bd8",
            "e0be395af1ce4da9a1d0fe46edd56736",
            "305cf2885fe64f41ba2e8862ad1e9a5b",
            "2fbca80deb2e43628f53a9dc385005d6",
            "4a2d82ddf82140a98da5b2238b5b5970",
            "e8fa72bab7c143e286a305a8726e2d04",
            "3bc46905803c44fe91ee57e9eec6ae4c",
            "46c7aa2c3a7b4b9481b0d3ef0903f857",
            "62d2cbe779b949a8aa17378d867a5e2f",
            "a4c0f7037bcf4532b583a212fb716818",
            "55f4c4419b80446d8d7df2523637ff21",
            "788ac0407be349128c165dd57ab54bad",
            "a9f12b58ca4c4deab13e35646fa2d3fd",
            "24c0ad987a774841bf15b56888c6e54d",
            "0064f75a64ad4ee296d87e097fded169",
            "1ac16c18421e49b794617fd5b29a38f5",
            "d100093a2082408698b7293fec9bc837",
            "d3722176ea4a42e09e12b1ac5d30be7f",
            "447e114aaa894763a8770f7371bccc51"
          ]
        },
        "id": "rVYpUhkG0O1m",
        "outputId": "a328db14-4d83-49dc-9490-d323c7d2bb86"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting XtremeDistil NSFW/Safe Content Classification Pipeline\n",
            "======================================================================\n",
            "Using model: microsoft/xtremedistil-l6-h384-uncased\n",
            "Output directory: models/xtremedistil_nsfw_safe_classification\n",
            "Task: Binary classification (Safe vs NSFW content)\n",
            "Loading dataset from dataset.csv...\n",
            "Error: Dataset file 'dataset.csv' not found!\n",
            "Creating a sample NSFW/Safe classification dataset for demonstration...\n",
            "Sample NSFW/Safe classification dataset created and saved as 'dataset.csv'\n",
            "Dataset shape: (45, 2)\n",
            "Label mapping: 0 = Safe, 1 = NSFW\n",
            "Number of classes detected: 2\n",
            "Splitting dataset: 20.0% for validation...\n",
            "Training set: 36 samples\n",
            "Validation set: 9 samples\n",
            "Loading XtremeDistil tokenizer and creating tokenized datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "640574d0334943979d6b6b934c48bd1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62d2cbe779b949a8aa17378d867a5e2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete!\n",
            "Sample tokenized text length: 11\n",
            "Initializing XtremeDistil model for multilingual classification training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/xtremedistil-l6-h384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-100062013.py:78: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12/12 00:08, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.687663</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.518519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.666395</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.584615</td>\n",
              "      <td>0.605128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.640733</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.673100</td>\n",
              "      <td>0.625543</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to models/xtremedistil_nsfw_safe_classification...\n",
            "Evaluating model performance...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics saved to metrics/xtremedistil_nsfw_safe_metrics.txt\n",
            "Validation Accuracy: 1.0000\n",
            "F1-Score (Macro): 1.0000\n",
            "Exporting XtremeDistil NSFW/Safe classification model to ONNX format...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-314980411.py:20: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model exported to: models/xtremedistil_nsfw_safe_model.onnx\n",
            "ONNX model size: 86.80 MB\n",
            "Converting XtremeDistil NSFW/Safe PyTorch model to TensorFlow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved intermediate TensorFlow model to models/xtremedistil_nsfw_safe_classification/tf_saved_model\n",
            "TFLite NSFW/Safe classification model successfully exported to: models/xtremedistil_nsfw_safe_model.tflite\n",
            "TFLite model size: 43.47 MB\n",
            "\n",
            "======================================================================\n",
            "XtremeDistil NSFW/Safe Content Classification Training Complete!\n",
            "✅ ONNX model: models/xtremedistil_nsfw_safe_model.onnx\n",
            "✅ TFLite model: models/xtremedistil_nsfw_safe_model.tflite\n",
            "\n",
            "Model checkpoints: models/xtremedistil_nsfw_safe_classification\n",
            "Metrics: metrics/xtremedistil_nsfw_safe_metrics.txt\n",
            "Final validation accuracy: 1.0000\n",
            "\n",
            "Model can classify content as:\n",
            "- 0: Safe content\n",
            "- 1: NSFW content\n",
            "\n",
            "Testing trained XtremeDistil NSFW/Safe classification model...\n",
            "Text 1: 'I absolutely love this product, it's amazing!'\n",
            "  -> Safe (confidence: 0.5414)\n",
            "  Probabilities: Safe=0.541, NSFW=0.459\n",
            "\n",
            "Text 2: 'This is a family-friendly educational video about science.'\n",
            "  -> Safe (confidence: 0.5467)\n",
            "  Probabilities: Safe=0.547, NSFW=0.453\n",
            "\n",
            "Text 3: 'Great customer service and fast delivery.'\n",
            "  -> Safe (confidence: 0.5421)\n",
            "  Probabilities: Safe=0.542, NSFW=0.458\n",
            "\n",
            "Text 4: 'The movie is appropriate for all age groups.'\n",
            "  -> Safe (confidence: 0.5353)\n",
            "  Probabilities: Safe=0.535, NSFW=0.465\n",
            "\n",
            "Text 5: 'This workspace follows safety guidelines.'\n",
            "  -> Safe (confidence: 0.5323)\n",
            "  Probabilities: Safe=0.532, NSFW=0.468\n",
            "\n",
            "Text 6: 'Me encanta este producto, es fantástico.'\n",
            "  -> Safe (confidence: 0.5448)\n",
            "  Probabilities: Safe=0.545, NSFW=0.455\n",
            "\n",
            "Text 7: 'Contenido educativo apropiado para toda la familia.'\n",
            "  -> Safe (confidence: 0.5465)\n",
            "  Probabilities: Safe=0.547, NSFW=0.453\n",
            "\n",
            "Text 8: 'Napakaganda ng produktong ito, sulit na sulit!'\n",
            "  -> Safe (confidence: 0.5425)\n",
            "  Probabilities: Safe=0.543, NSFW=0.457\n",
            "\n",
            "Text 9: 'Magandang palabas para sa buong pamilya.'\n",
            "  -> Safe (confidence: 0.5500)\n",
            "  Probabilities: Safe=0.550, NSFW=0.450\n",
            "\n",
            "Text 10: 'J'adore ce produit, il est formidable!'\n",
            "  -> Safe (confidence: 0.5438)\n",
            "  Probabilities: Safe=0.544, NSFW=0.456\n",
            "\n",
            "Text 11: 'Contenu familial et éducatif.'\n",
            "  -> Safe (confidence: 0.5432)\n",
            "  Probabilities: Safe=0.543, NSFW=0.457\n",
            "\n",
            "Text 12: 'This contains explicit adult content not suitable for minors.'\n",
            "  -> NSFW (confidence: 0.5218)\n",
            "  Probabilities: Safe=0.478, NSFW=0.522\n",
            "\n",
            "Text 13: 'Inappropriate sexual references and mature themes.'\n",
            "  -> NSFW (confidence: 0.5322)\n",
            "  Probabilities: Safe=0.468, NSFW=0.532\n",
            "\n",
            "Text 14: 'Contains graphic violence and disturbing imagery.'\n",
            "  -> NSFW (confidence: 0.5356)\n",
            "  Probabilities: Safe=0.464, NSFW=0.536\n",
            "\n",
            "Text 15: 'Adult-oriented material with explicit language.'\n",
            "  -> NSFW (confidence: 0.5124)\n",
            "  Probabilities: Safe=0.488, NSFW=0.512\n",
            "\n",
            "Text 16: 'Mature content with sexual themes.'\n",
            "  -> NSFW (confidence: 0.5149)\n",
            "  Probabilities: Safe=0.485, NSFW=0.515\n",
            "\n",
            "Text 17: 'Violent content not suitable for children.'\n",
            "  -> NSFW (confidence: 0.5028)\n",
            "  Probabilities: Safe=0.497, NSFW=0.503\n",
            "\n",
            "\n",
            "Program execution completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create zip of entire content folder\n",
        "!zip -r /content/colab_content_microsoft.zip /content/\n",
        "\n",
        "# Download the zip\n",
        "from google.colab import files\n",
        "files.download('/content/colab_content_microsoft.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPb1bRri2ZMh",
        "outputId": "cb42a3eb-e9dc-4ebf-95b8-7b60314a9c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/.config/ (stored 0%)\n",
            "  adding: content/.config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
            "  adding: content/.config/config_sentinel (stored 0%)\n",
            "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/active_config (stored 0%)\n",
            "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/default_configs.db (deflated 98%)\n",
            "  adding: content/.config/configurations/ (stored 0%)\n",
            "  adding: content/.config/configurations/config_default (deflated 15%)\n",
            "  adding: content/.config/gce (stored 0%)\n",
            "  adding: content/.config/logs/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.09.16/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.09.16/13.39.51.530260.log (deflated 92%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.25.424362.log (deflated 86%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.37.615954.log (deflated 57%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.15.959626.log (deflated 58%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.38.414999.log (deflated 56%)\n",
            "  adding: content/.config/logs/2025.09.16/13.40.27.693438.log (deflated 58%)\n",
            "  adding: content/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/metrics/ (stored 0%)\n",
            "  adding: content/metrics/xtremedistil_nsfw_safe_metrics.txt (deflated 62%)\n",
            "  adding: content/models/ (stored 0%)\n",
            "  adding: content/models/xtremedistil_nsfw_safe_model.tflite (deflated 8%)\n",
            "  adding: content/models/xtremedistil_nsfw_safe_classification/ (stored 0%)\n",
            "  adding: content/models/xtremedistil_nsfw_safe_classification/checkpoint-12/ (stored 0%)\n",
            "  adding: content/models/xtremedistil_nsfw_safe_classification/checkpoint-12/model.safetensors (deflated 8%)\n",
            "  adding: content/models/xtremedistil_nsfw_safe_classification/checkpoint-12/scheduler.pt (deflated 62%)\n",
            "  adding: content/models/xtremedistil_nsfw_safe_classification/checkpoint-12/training_args.bin (deflated 53%)\n",
            "  adding: content/models/xtremedistil_nsfw_safe_classification/checkpoint-12/scaler.pt (deflated 64%)\n",
            "  adding: content/models/xtremedistil_nsfw_safe_classification/checkpoint-12/vocab.txt (deflated 53%)\n",
            "  adding: content/models/xtremedistil_nsfw_safe_classification/checkpoint-12/optimizer.pt"
          ]
        }
      ]
    }
  ]
}